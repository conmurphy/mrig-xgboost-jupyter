{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96d2388",
   "metadata": {},
   "source": [
    "# Hands On XGBoost\n",
    "### Hands On Notebook\n",
    "\n",
    "m|rig GmbH\n",
    "\n",
    "Gesa Murphy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639aa704",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Laden der Python-Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliotheken für Machine Learning und Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders.woe import WOEEncoder #wird nur im optionalen Log Reg Teil verwendet.\n",
    "\n",
    "# xgboost Biblothek\n",
    "import xgboost as xgb\n",
    "\n",
    "# Bibliotheken für Visualisierung\n",
    "from plot_functions import plot_features # Eigene Plot-Funktion\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from xgboost import to_graphviz\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Bibliothek für SHAP values (XAI)\n",
    "import shap\n",
    "\n",
    "# Setze Anzeigeoptionen für Pandas\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11613a4",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Lade und analysiere den Datensatz \"Taiwanese Credit Card Default Data\"\n",
    "Importiere die csv \"default of credit card clients preprocessed.csv\" als Data.Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd91d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade csv als Data.Frame\n",
    "df = pd.read_csv(\"default of credit card clients preprocessed v3.csv\", sep=\";\")\n",
    "\n",
    "# Die Merkmale des Datensatzes werden in ID (primary key), metrische und kategoriale erklärende Merkmale sowie die Zielvariable (abhängige Variable) unterteilt.\n",
    "id_col = 'ID'\n",
    "met_features = [col for col in df.drop(['ID', 'default'], axis=1).select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns.tolist() ]\n",
    "cat_features = df.select_dtypes(include=['object', 'category']).columns.tolist() \n",
    "target_col = 'default'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038452d5",
   "metadata": {},
   "source": [
    "### Merkmalserläuterungen\n",
    "- ID: primary key\n",
    "- LIMIT_BAL Kreditlimit \n",
    "- Sex: Geschlecht\n",
    "- EDUCATION: höchster Bildungsabschluss\n",
    "- MARRIAGE: Familienstand\n",
    "- AGE: Alter in Jahren\n",
    "- payment_status_mx: Verzugsstatus im x. Monat vor Ausfall\n",
    "    - -1: Rechtzeitig alles bezahlt ('paid on time')\n",
    "    - 0: Nur das nötigste gezahlt ('use of revolving credit')\n",
    "    - 1-8: Anzahl Monate in Überziehung\n",
    "    \n",
    "- bill_amount_mx: Offener Betrag im x. Monat vor Ausfall\n",
    "- payment_amount_mx: Bezahlter Betrag im x. Monat vor Ausfall\n",
    "- default: Zielvariable (1 - Ausfall, 0 - kein Ausfall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f5d43a",
   "metadata": {},
   "source": [
    "Aufgabe: \n",
    "\n",
    "Analysiere den Datensatz näher:\n",
    "- Verwende die head-Methoden des DateFrames df\n",
    "- Verwende die describe-Methode des DateFrames df auf den kategorialen Merkmalen verwende .astype(\"object\") um alle kategorialen Features als solche zu betrachten.\n",
    "- Verwende die describe-Methode des DateFrames df auf den numerischen Merkmalen inkl. percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibt die ersten 5 Zeilen des DataFrames aus\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f675b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung der kategorialen Merkmale\n",
    "df[cat_features].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung der metrischen Merkmale\n",
    "df[met_features].describe(include='all', percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1534f1",
   "metadata": {},
   "source": [
    "Aufgabe: Erzeuge Grafiken zur Verteilung der einzelnen Merkmale.\n",
    "\n",
    "Nutze hierzu die in plot_functions.py vordefinierten Funktion \"plot_features\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df,target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3bf02",
   "metadata": {},
   "source": [
    "Achtung Korrelation: Sind viele Features miteinander korreliert, hat die logistische Regression manchmal Problem. (Zum Glück gibt es XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df[met_features].corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a23008",
   "metadata": {},
   "source": [
    "Fragen Aufgabe 2:\n",
    "- Zu welchen Merkmalen liegen Missings vor?\n",
    "- Welche Merkmale sehen schon besonders trennscharf aus?\n",
    "- Gehören die Missings eher zu den positiven oder negativen Merkmalen (Was ist ihre Ausfallrate im Vergleich zu den anderen Ausprägungen?)\n",
    "- Welche Merkmale sind miteinander korreliert?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb75952",
   "metadata": {},
   "source": [
    "## Aufgabe 3: XGBoost\n",
    "Trainiere ein xgboost-Modell. Speichere hierzu die erklärenden Variablen unter X_xgb und die Zielvariablen unter y ab.\n",
    "Es gibt mind. zwei Möglichkeiten mit Objektvariablen umzugehen:\n",
    "- Variante 1: kategorische Variablen mit OneHot-Encoding transformieren\n",
    "- Variante 2: kategorische Variablen direkt verwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8517b8",
   "metadata": {},
   "source": [
    "### 3.1 Variante 1: kategorische Variablen mit OneHot-Encoding transformieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot-Encoding der kategorialen Variablen inklusive Dummy-Variable für fehlende Werte\n",
    "X_xgb_mD = pd.get_dummies(df.drop([id_col, target_col], axis = 1), columns=cat_features, dummy_na=True, drop_first=True, prefix=cat_features).copy()\n",
    "y_xgb_mD =  df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "X_train_xgb_mD, X_test_xgb_mD, y_train_xgb_mD, y_test_xgb_mD = train_test_split(\n",
    "    X_xgb_mD, y_xgb_mD, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd885c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelldesign und Training\n",
    "xgb_model_mD = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellevaluation\n",
    "y_probs_mD = xgb_model_mD.predict_proba(X_test_xgb_mD)[:, 1]\n",
    "\n",
    "gini = 2 * roc_auc_score(y_test_xgb_mD, y_probs_mD) - 1\n",
    "print(f\"Gini: {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81fc7c",
   "metadata": {},
   "source": [
    "### 3.2 Variante 2: kategorische Variablen direkt verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ersetze object column type mit category\n",
    "X_xgb = pd.concat([df[met_features], df[cat_features].astype('category')], axis=1)\n",
    "y_xgb =  df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(\n",
    "    X_xgb, y_xgb, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelldesign und Training\n",
    "xgb_model ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellevaluation\n",
    "y_probs = xgb_model.predict_proba(X_test_xgb)[:, 1]\n",
    "\n",
    "gini = 2 * roc_auc_score(y_test_xgb, y_probs) - 1\n",
    "print(f\"Gini: {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d664ea",
   "metadata": {},
   "source": [
    "Frage Aufgabe 3.1 / 3.2:\n",
    "- Was sind mögliche Vor- und Nachteile der beiden Varianten?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53e29f",
   "metadata": {},
   "source": [
    "### 3.3 Xgboost-Modell verstehen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509941d",
   "metadata": {},
   "source": [
    "Aufgabe: Visualisiere den ersten Baum sowie die Bäume 10 / 50 /100 mit \"to_graphviz\".\n",
    "\n",
    "Tipp: Verwende \"size\" um die Größe der Grafik anzupassen und rankdir='LR' um die Ausrichtung zu ändern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5316b",
   "metadata": {},
   "source": [
    "Erklärung der Darstellung: Die Darstellung von Bäumen mit to_graphviz und plot_tree von XGB ist meiner Meinung nach noch nicht ideal und etwas verwirrend. Abzweigungen mit kategorischen Merkmalen zeigen zusätzlich zur enthaltenen Menge noch einen Wert für gain und cover an. Metrische Merkmale nicht.\n",
    "\n",
    "Hinweis: Die Leaf Values sind Log Odds. Wendet man auf sie die Sigmoid Funktion an, erhält man Wahrscheinlichkeiten zwischen 0 und 1. Leaf Werte kleiner als 0 führen zu Wahrscheinlichkeiten unter 50%. Je höher der Leaf Value, für desto wahrscheinlicher wird ein Ausfall gehalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ec83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellung des ersten Baumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c38e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellung des 10./20./100. Baumes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ceec0",
   "metadata": {},
   "source": [
    "Aufgabe: Visualisiere die Feature Importance nach \"gain\". Du kannst auch die Importance mit \"cover\" oder \"weight\" betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5992ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2237358e",
   "metadata": {},
   "source": [
    "Aufgabe 3.3:\n",
    "- Welche Auffälligkeiten gibt es beim Vergleich der Bäume mit unterschiedlichen Iterationsnummern?\n",
    "- Plausiblisiere die Feature Importance fachlich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96e86f",
   "metadata": {},
   "source": [
    "Antwort 3.3:\n",
    "- Die Absolutwerte in den Leafs nehmen tendenziell ab.\n",
    "- Aktuellere Features haben einen höheren Impact auf das Modell. Payment_status ist eng mit dem Ausfallkriterium verbunden und hat daher einen höheren Einfluss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895a7b2",
   "metadata": {},
   "source": [
    "### 3.4 xgboost-Modell optimieren\n",
    "\n",
    "Baumstruktur:\n",
    "\n",
    "\n",
    "| Parameter           | Beschreibung                                                   | Typischer Bereich | Default |\n",
    "|---------------------|------------------------------------------------------------------|-------------------|---------|\n",
    "| `n_estimators`      | Anzahl der Bäume (Boosting-Runden)                              | 50 – 1000         | `100`   |\n",
    "| `max_depth`         | Maximale Tiefe der Bäume                                        | 2 – 15            | `6`     |\n",
    "| `min_child_weight`  | Minimale Summe der Gewichte pro Blattknoten                    | 1 – 10            | `1`     |\n",
    "| `subsample`         | Anteil der Trainingsdaten, die pro Baum verwendet werden       | 0.5 – 1           | `1.0`   |\n",
    "| `colsample_bytree`  | Anteil der Merkmale, die pro Baum verwendet werden             | 0.3 – 1           | `1.0`   |\n",
    "| `colsample_bylevel` | Anteil der Merkmale pro Level (Tiefe)                          | 0.3 – 1           | `1.0`   |\n",
    "| `colsample_bynode`  | Anteil der Merkmale pro Knoten                                 | 0.3 – 1           | `1.0`   |\n",
    "| `scale_pos_weight`  | Gewichtung der positiven Klasse (bei Ungleichgewicht)          | 1 – 100 (je nach Unbalance) | `1.0` |\n",
    "\n",
    "Lernrate und Regularisierung:\n",
    "\n",
    "| Parameter       | Beschreibung                                               | Typischer Bereich | Default |\n",
    "|-----------------|------------------------------------------------------------|-------------------|---------|\n",
    "| `learning_rate` | Lernrate / Schrittweite des Boostings                      | 0.01 – 0.3        | `0.3`   |\n",
    "| `gamma`         | Mindestverlustreduktion für einen Split (`min_split_loss`) | 0 – 10            | `0.0`   |\n",
    "| `reg_alpha`     | L1-Regularisierung (Lasso) auf Blattwerte                  | 0 – 10            | `0.0`   |\n",
    "| `reg_lambda`    | L2-Regularisierung (Ridge) auf Blattwerte                  | 0 – 10            | `1.0`   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e59770",
   "metadata": {},
   "source": [
    "Es folgt Code für ein einfaches Gridsearch. Mit den vorgeschlagenen Parametern dauert es etwa 2 Minuten. Versuche den Code anzupassen (passe dazu das param_grid an) und auf ein noch besseres Ergebnis zu kommen.\n",
    "\n",
    "Aber je mehr Parameter oder Werte du mit reinnimmst, desto länger läuft der Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basis-Modell für Grid Search\n",
    "xgb_model_GS = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    enable_categorical=True \n",
    ")\n",
    "\n",
    "# Parameter-Grid definieren - hier nach Bedarf Änderungen vornehmen\n",
    "param_grid = {\n",
    "    'n_estimators': [250], # [100, 250, 500]\n",
    "    'max_depth': [ 2, 3], #[3,4, 5,6 7],\n",
    "    'gamma': [1, 2], #  [0, 1, 2, 3, 4, 5],\n",
    "    'colsample_bytree': [0.8, 1.0], # [0.8],\n",
    "    'learning_rate': [0.1, 0.1], # [0.01, 0.05, 0.1],\n",
    "    'reg_alpha': [2, 3], # [0, 1, 2, 3, 4, 5],\n",
    "    'reg_lambda': [1, 2] #[0, 3, 5] \n",
    "}\n",
    "\n",
    "# Grid Search konfigurieren\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model_GS,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3, # Cross-Validation mit 3 Folds\n",
    "    verbose=2, # detaillierter Output\n",
    "    n_jobs=-1 # alle verfügbaren Kerne nutzen \n",
    ")\n",
    "\n",
    "# Training 100 fits < 1 min\n",
    "grid_search.fit(X_train_xgb, y_train_xgb)\n",
    "\n",
    "# Beste Parameter & Genauigkeit\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste CrossValidation-Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "# Test-Performance\n",
    "best_model = grid_search.best_estimator_\n",
    "y_probs = best_model.predict_proba(X_test_xgb)[:, 1]\n",
    "\n",
    "gini = 2 * roc_auc_score(y_test_xgb, y_probs) - 1\n",
    "print(f\"Gini: {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faff156",
   "metadata": {},
   "source": [
    "Schau dir das best_model einmal an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd32404",
   "metadata": {},
   "source": [
    "## Aufgabe 4: Erklärbarkeit des Modells mit Shapley values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b144007",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029674b",
   "metadata": {},
   "source": [
    "Verwende das best_model. Es sollte vermutlich kategorische Merkmale verwendet haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Werte berechnen\n",
    "explainer_xgb = shap.Explainer(best_model)\n",
    "shap_values_xgb = explainer_xgb(X_test_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfe1cc",
   "metadata": {},
   "source": [
    "Betrachte die Feature Importance mit SHAP über den summary_plot (plot_type='bar'). Vergleiche mit der feature_importance die direkt von XGBoost kam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cd101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8116514",
   "metadata": {},
   "source": [
    "Betrachte den Einfluss der SHAP Value nach Feature Werten über den beeswarm Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be1afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbcc7e57",
   "metadata": {},
   "source": [
    "Vergleiche den Beeswarm Plot des best_model mit dem Model mit dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_xgb_mD = shap.Explainer(xgb_model_mD)\n",
    "shap_values_xgb_mD = explainer_xgb_mD(X_test_xgb_mD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values_xgb_mD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ff03a",
   "metadata": {},
   "source": [
    "Betrachte die Verteilung der Shap Values bei einem einzelnen Feature, dem mit der größten Feature Importance: (zurück zum Best Model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f728458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.plots.scatter(shap_values_xgb[:, 'ersetze hier den namen des features mit höchster importance'],color =y_test_xgb.to_numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d264425",
   "metadata": {},
   "source": [
    "## Aufgabe 5: Optional: Logistische Regression\n",
    "\n",
    "Dieser Teil des Notebooks ist optional. Wir haben allen Code hier drin gelassen, da wir mit diesem Teil nur aufzeigen wollen, was bei logisitischer Regression, die in Banken üblicherweise für die Schätzung eines PD Modells genutzt wird, alles extra getan werden muss. Im Gegensatz zu XGBoost können wir die Daten nicht einfach in ein einfaches XGB Modell reinnehmen, sondern müssen mit Missings und anderen Problemen vorher umgehen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f629edc",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 Einfaches Logistisches Regressionsmodell\n",
    "Baue zunächst ein logistisches Regressionsmodell mit einem Minimum an Datenvorbereitung (alle kategorischen Feature in dummy Variablen umwandeln)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d434c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot-Encoding der kategorialen Variablen inklusive Dummy-Variable für fehlende Werte\n",
    "X_lr_simple = pd.get_dummies(df.drop([id_col, target_col], axis = 1), columns=cat_features, drop_first=True, prefix=cat_features).copy()\n",
    "y_lr_simple =  df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train-Test-Split\n",
    "X_slr_train, X_slr_test, y_slr_train, y_slr_test = train_test_split(\n",
    "    X_lr_simple,y_lr_simple, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346507ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelldesign und Training\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_slr_train, y_slr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cf24d6",
   "metadata": {},
   "source": [
    "Dieser Fehler kommt, weil na enthalten sind. Also: ganz so einfach geht es nicht. Wir können die nas ersetzen, z.B. durch den Median oder Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in met_features:\n",
    "    X_lr_simple[feature] = X_lr_simple[feature].fillna(X_lr_simple[feature].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ca9e8",
   "metadata": {},
   "source": [
    "Wiederhole Train test split und Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707aaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "X_slr_train, X_slr_test, y_slr_train, y_slr_test = train_test_split(\n",
    "    X_lr_simple,y_lr_simple, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelldesign und Training\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_slr_train, y_slr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f3c13",
   "metadata": {},
   "source": [
    "Diesmal sollte eine Warnung gekommen sein, dass das Modell nicht konvergiert ist. (viele korrelierende Variablen). Man bekommt trotzdem eine Prediction (siehe nächstes Codefeld), aber eben nicht die beste.\n",
    "Es gibt viele Lösungen, z.B. \n",
    "- max_iter hochsetzen\n",
    "- korrelierende Variablen rausschmeißen (z.B. nur 1. Monat vor Ausfall benutzen (payment_status_m1, bill_amount_m1,..))\n",
    "- Alle features skalieren mit\n",
    "X_scaled = scaler.fit_transform(X_lr_simple)\n",
    "X_slr_train, X_slr_test, y_slr_train, y_slr_test = train_test_split(\n",
    "    X_scaled,y_lr_simple, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "Oder aber, wie in 5.2, mehr Datenaufbereitung betreiben und alle Merkmale gruppieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ee150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellevaluation\n",
    "y_probs = lr.predict_proba(X_slr_test)[:, 1]\n",
    "\n",
    "gini = 2 * roc_auc_score(y_slr_test, y_probs) - 1\n",
    "print(f\"Gini: {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea9467",
   "metadata": {},
   "source": [
    "### 5.2 Logistisches Regressionsmodell mit Datenaufbereitung\n",
    "Baue ein logistisches Regressionsmodell mit einer ausführlicheren Datenaufbereitung. Dies entspricht sicher noch lange nicht einer vollständigen PD Modellierung, aber die Ergebnisse kommen dem schon näher.\n",
    "\n",
    "Die Features werden alle gruppiert um dann später mit einem WOE Encoder einen bestimmten neuen Wert zu erhalten, der dann als Feature eingeht statt den Originalfeatures.\n",
    "Die Behandlung von Missings wird mit .fillna(Wert_den_missing_erhalten_sollen) geregelt, also Missings werden nicht ausgeschlossen, sondern (zunächst) durch passende Kategorien (others) oder Mittlere Werte (bei good/bad/very bad ist bad der mittlere Wert). Falls ihr an dieser Stelle noch etwas Zeit habt, könnt ihr ja mal probieren, wieviel besser oder schlechter das Modell wird, wenn man die .fillna der payment status features auf good oder very bad setzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = df.copy()\n",
    "\n",
    "# Gruppiere Merkmale\n",
    "\n",
    "# SEX, EDUCATION, MARRIAGE\n",
    "df_lr['grp_SEX'] = df_lr['SEX'] # in einem richtigen PD Modell würde normalerweise das Geschlecht nicht eingehen.\n",
    "\n",
    "df_lr['grp_EDUCATION'] = df_lr['EDUCATION'].replace({\n",
    "    'graduate school': 'higher',\n",
    "    'university': 'higher',\n",
    "    'high school': 'medium and others',\n",
    "    'others': 'medium and others'\n",
    "}).fillna('medium and others') # fehlende Werte werden der Gruppe 'medium and others' zugeordnet\n",
    "\n",
    "df_lr['grp_MARRIAGE'] = df_lr['MARRIAGE'].replace({\n",
    "    'married': 'married',\n",
    "    'single': 'single and others',\n",
    "    'others': 'single and others'\n",
    "}).fillna('single and others') # fehlende Werte werden der Gruppe 'single and others' zugeordnet\n",
    "\n",
    "# Gruppiere numerische Merkmale\n",
    "df_lr['grp_AGE'] = pd.cut(df_lr['AGE'], bins=[0, 25, 40, 50, 60, np.inf])\n",
    "\n",
    "df_lr['grp_LIMIT_BAL'] = pd.cut(df_lr['LIMIT_BAL'], bins=[0, 25000, 50000, 100000, 150000, 300000, np.inf])\n",
    "\n",
    "for feature in df_lr.columns:\n",
    "    if feature.startswith('bill_amount'):\n",
    "        df_lr['grp_' + feature] = pd.cut(df_lr[feature], bins=[-np.inf, 50000, np.inf])\n",
    "    if feature.startswith('payment_amount'):\n",
    "        df_lr['grp_' + feature] = pd.cut(df_lr[feature], bins=[0, 1000, 3000, 5000, 10000, np.inf])\n",
    "    if feature.startswith('payment_status'): # Fokus auf payment_status Merkmale\n",
    "        df_lr['grp_' + feature] = df_lr[feature].replace({\n",
    "            -1: 'good',\n",
    "            0: 'good',\n",
    "            1: 'bad',\n",
    "            2: 'very bad',\n",
    "            3: 'very bad',\n",
    "            4: 'very bad',\n",
    "            5: 'very bad',\n",
    "            6: 'very bad',\n",
    "            7: 'very bad',\n",
    "            8: 'very bad'\n",
    "        }).fillna('bad')        # fehlende Werte der mittleren Kategorie zuordnen\n",
    "\n",
    "# Reduziere Spalten auf gruppierte Merkmale\n",
    "df_lr_grp = df_lr.loc[:, df_lr.columns.str.startswith('grp_')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "X_lr_train, X_lr_test, y_lr_train, y_lr_test = train_test_split(\n",
    "        df_lr_grp, df_lr[target_col], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelldesign und Training\n",
    "# Das Logistische Regressionsmodell wird in einer Pipeline zusammen mit dem WOE-Encoder trainiert.\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"woe\", WOEEncoder(\n",
    "        cols=df_lr_grp.columns.tolist(),\n",
    "        handle_missing=\"value\",\n",
    "        handle_unknown=\"value\",\n",
    "        randomized=False\n",
    "    )),\n",
    "    (\"logit\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_lr_train, y_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a206cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellevaluation\n",
    "y_probs = pipeline.predict_proba(X_lr_test)[:, 1]\n",
    "\n",
    "gini = 2 * roc_auc_score(y_lr_test, y_probs) - 1\n",
    "print(f\"Gini: {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e57f56",
   "metadata": {},
   "source": [
    "### SHAP Plots for Log REG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4daa18",
   "metadata": {},
   "source": [
    "Hier sind die SHAP-Plots nochmal für die logistische Regression. Man sieht deutlich, dass die logistische Regression lineare Zusammenhänge abbildet: Die Beiträge der Merkmale sind konsistent und richten sich direkt nach den Koeffizienten.\n",
    "Im Gegensatz dazu zeigt XGBoost ein deutlich komplexeres Bild: Die SHAP-Werte für ein und dasselbe Merkmal variieren stark zwischen Beobachtungen, da XGBoost nichtlineare Beziehungen und Wechselwirkungen zwischen Variablen modelliert. Dadurch entstehen individuelle, kontextabhängige Erklärungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd27c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Werte berechnen aus der Logistischen Regression\n",
    "X_train_transformed = pipeline.named_steps['woe'].transform(X_lr_train)\n",
    "X_test_transformed = pipeline.named_steps['woe'].transform(X_lr_test)\n",
    "\n",
    "explainer_lr = shap.Explainer(pipeline.named_steps['logit'], X_train_transformed)\n",
    "shap_values_lr = explainer_lr(X_test_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.plots.scatter(shap_values_lr[:, 'grp_payment_status_m1'],color =y_test_xgb.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zum Vergleich noch einmal XGBoost\n",
    "shap.plots.scatter(shap_values_xgb[:, 'payment_status_m1'],color =y_test_xgb.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zum Vergleich noch einmal XGBoost\n",
    "shap.plots.beeswarm(shap_values_xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
